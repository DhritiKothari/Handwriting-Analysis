from flask import Flask, request, jsonify
import joblib
import cv2
import numpy as np
import os
import pandas as pd
from flask_cors import CORS
from pathlib import Path

# --- 1. CONFIGURATION & LOAD FILES ---
app = Flask(__name__)
CORS(app)
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True

# Get the directory where main.py is currently located
CURRENT_DIR = Path(__file__).parent 

# Load the files from the SAME folder as main.py
# Ensure these were generated by your latest handwriting_analysis.py run
model = joblib.load(CURRENT_DIR / 'optimized_handwriting_model.pkl')
scaler = joblib.load(CURRENT_DIR / 'scaler.pkl')
le = joblib.load(CURRENT_DIR / 'label_encoder.pkl')

def get_thresholds():
    # Targets the CSV in the SAME folder as main.py for stability
    df = pd.read_csv(CURRENT_DIR / "final_combined_features.csv") 
    return {
        'slant': df['slant'].median(),
        'baseline': df['baseline'].median(),
        'spacing': df['spacing'].median(),
        'stroke': df['stroke'].median(),
        'size': df['size'].median(),
        'zonal_ratio': df['zonal_ratio'].median()
    }
thresholds = get_thresholds()

# --- 2. FEATURE EXTRACTION FUNCTIONS (Synced with handwriting_analysis.py) ---

def extract_slant(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 0.0
    edges = cv2.Canny(img, 50, 150)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)
    if lines is None: return 0.0
    angles = [(line[0][1] - np.pi / 2) * (180 / np.pi) for line in lines[:50]]
    valid = [a for a in angles if -45 < a < 45]
    return float(np.mean(valid)) if valid else 0.0

def extract_baseline(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 0.0
    h, w = img.shape
    roi = img[int(h*0.15):int(h*0.85), :]
    ys, xs = np.where(roi > 0)
    if len(xs) < 200: return 0.0
    unique_x, counts = np.unique(xs, return_counts=True)
    valid_columns = unique_x[counts > 5]
    bx, by = [], []
    for col in valid_columns:
        bx.append(col); by.append(np.max(ys[xs == col]))
    slope, _ = np.polyfit(np.array(bx), np.array(by), 1)
    return float(slope)

def extract_word_spacing(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 0.0
    h, w = img.shape
    roi = img[int(h*0.15):int(h*0.85), :]
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 3))
    dilated = cv2.dilate(roi, kernel, iterations=1)
    num_labels, _, stats, _ = cv2.connectedComponentsWithStats(dilated)
    boxes = sorted([(stats[i, 0], stats[i, 2]) for i in range(1, num_labels) if stats[i, 4] > 400], key=lambda b: b[0])
    spacings = [boxes[i+1][0] - (boxes[i][0] + boxes[i][1]) for i in range(len(boxes)-1) if 5 < (boxes[i+1][0] - (boxes[i][0] + boxes[i][1])) < 250]
    return float(np.mean(spacings)) if spacings else 0.0

def extract_stroke_thickness(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 0.0
    h, w = img.shape
    roi = img[int(h*0.15):int(h*0.85), :]
    dist = cv2.distanceTransform(roi, cv2.DIST_L2, 5)
    return float(2 * np.mean(dist[dist > 0.5])) if np.any(dist > 0.5) else 0.0

def extract_size(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 0.0
    h, w = img.shape
    roi = img[int(h*0.15):int(h*0.85), :]
    _, _, stats, _ = cv2.connectedComponentsWithStats(roi)
    heights = [stats[i, 3] for i in range(1, len(stats)) if stats[i, 4] > 20 and stats[i, 3] > 5]
    return float(np.median(heights)) if heights else 0.0

def extract_zonal_ratio(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None: return 1.0
    h, w = img.shape
    roi = img[int(h*0.15):int(h*0.85), :]
    upper_zone = roi[0:int(h*0.35), :]
    lower_zone = roi[int(h*0.65):, :]
    u_ink, l_ink = np.count_nonzero(upper_zone), np.count_nonzero(lower_zone)
    return float(u_ink / l_ink) if l_ink > 0 else 1.0

# --- 3. EXPLANATION FUNCTION ---
def explain_prediction(feat_list):
    reasons = []
    # Order: [slant, baseline, spacing, stroke, size, zonal_ratio]
    if feat_list[0] > thresholds['slant']:
        reasons.append("Right-slant: Emotional expressiveness (Extrovert trait)")
    else:
        reasons.append("Vertical/Left-slant: Emotional restraint (Introvert trait)")
        
    if feat_list[2] < thresholds['spacing']:
        reasons.append("Narrow spacing: High sociability (Extrovert trait)")
    else:
        reasons.append("Wide spacing: Need for personal space (Introvert trait)")
        
    if feat_list[3] > thresholds['stroke']:
        reasons.append("Thick strokes: High energy and confidence (Extrovert trait)")
    else:
        reasons.append("Thin strokes: Cautious and sensitive (Introvert trait)")
        
    if feat_list[4] > thresholds['size']:
        reasons.append("Large size: Desire for social recognition (Extrovert trait)")
    else:
        reasons.append("Small size: Focus and concentration (Introvert trait)")

    if feat_list[5] < thresholds['zonal_ratio']:
        reasons.append("Low Zonal Ratio: Focus on social/physical drive (Extrovert trait)")
    else:
        reasons.append("High Zonal Ratio: Focus on intellectual/internal thought (Introvert trait)")
        
    if feat_list[1] < thresholds['baseline']:
        reasons.append("Rising baseline: Optimism and high energy")
    else:
        reasons.append("Stable/Descending baseline: Emotional control or fatigue")
    return reasons

# --- 4. FLASK ENDPOINT ---
@app.route('/predict', methods=['POST'])
def predict():
    if 'image' not in request.files:
        return jsonify({"error": "No image uploaded"}), 400
    
    file = request.files['image']
    img_path = "temp_predict.png"
    file.save(img_path)
    
    try:
        # 1. Extract raw features (all 6)
        raw_feats = [
            extract_slant(img_path),
            extract_baseline(img_path),
            extract_word_spacing(img_path),
            extract_stroke_thickness(img_path),
            extract_size(img_path),
            extract_zonal_ratio(img_path)
        ]
        
        # 2. Sanity check: Ensure finite floats
        feat_list = [float(val) if (val is not None and np.isfinite(val)) else 0.0 for val in raw_feats]

        # 3. Get Probabilities using predict_proba
        features_scaled = scaler.transform([feat_list])
        probs = model.predict_proba(features_scaled)[0]
        
        # 4. Create percentage dictionary for the Frontend bars
        percentages = {
            class_name: f"{round(float(prob) * 100, 2)}%" 
            for class_name, prob in zip(le.classes_, probs)
        }
        
        # 5. Get final label (highest probability)
        result = le.inverse_transform([np.argmax(probs)])[0]
        
        # 6. Generate trait explanations
        reasons = explain_prediction(feat_list)
        
        if os.path.exists(img_path):
            os.remove(img_path)
            
        return jsonify({
            "personality": result,
            "probability_distribution": percentages, # For your React progress bars
            "details": reasons
        })
        
    except Exception as e:
        print(f"Prediction Error: {e}")
        if os.path.exists(img_path):
            os.remove(img_path)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=False)